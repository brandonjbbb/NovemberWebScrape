Web Scraping and NLP Project

Description

This project demonstrates web scraping and natural language processing (NLP) techniques using Python. Key features include:

Token and Lemma Frequency Analysis: Identify the most frequent words and base forms in the text.
Sentence Scoring: Assign scores to sentences based on interesting tokens and lemmas.
Data Visualization: Generate histograms to analyze distributions.
Libraries Used: spaCy, BeautifulSoup, matplotlib, pickle, requests, and more.
This repository provides reproducible workflows for scraping and analyzing textual data efficiently.

Usage

Follow these steps to use the repository:

Clone the Repository:
git clone https://github.com/brandonjbbb/NovemberWebScrape.git
Set Up the Environment:
Make sure Python 3.8+ is installed.
Install the required libraries:
pip install -r requirements.txt
(Alternatively, manually install libraries like spaCy, BeautifulSoup, matplotlib, etc.)
Run Jupyter Notebooks:
Open Jupyter Notebook:
jupyter notebook
Navigate to the .ipynb files and execute them step-by-step.
View Executed Notebooks:
If you don't wish to run the notebooks, view the exported .html files directly in your browser.
Files

The repository contains the following files:

File Name	Description
notebook_name.ipynb	Jupyter Notebook containing the complete analysis and code execution.
notebook_name.html	Exported HTML version of the notebook for easy, browser-based review.
README.md	Detailed documentation of the project, usage instructions, and contact info.
Technologies Used

Python Libraries:
spaCy for NLP tasks
BeautifulSoup for web scraping
matplotlib for data visualization
pickle for saving serialized data
requests for fetching HTML content
Tools:
Jupyter Notebook for interactive coding
Git and GitHub for version control
HTML for rendering notebook exports
Contact

For questions, feedback, or collaboration opportunities, feel free to reach out:

Name: Brandon
Email: S576001@nwmissouri.edu
GitHub Profile: brandonjbbb
Acknowledgments

Special thanks to professors, colleagues, and contributors for their support and feedback during the project.

